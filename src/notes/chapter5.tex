\documentclass[
	lecture={5},
	title={Discrete Random Variables}
]{msf502notes}

\begin{document}

\setcounter{chapter}{4}
%<*Chapter-5>
\chapter{Discrete Random Variables}\label{ch:discrete-random-variables}
\begin{objectives}
	\item Distinguish between discrete and continuous random variables.
	\item Describe the probability distribution of a discrete random variable.
	\item Calculate and interpret summary measures for a discrete random variable.
	\item Differentiate among risk neutral, risk averse, and risk loving consumers.
	\item Compute summary measures to evaluate portfolio returns.
	\item Describe the binomial distribution and compute relevant probabilities.
	\item Describe the Poisson distribution and compute relevant probabilities.
\end{objectives}

\section{Random Variables and Discrete Probability Distributions}\label{sec:random-variables-and-discrete-probability-distributions}
\lo{Distinguish between discrete and continuous random variables.}
\begin{itemize}
	\item Random Variable
	\begin{itemize}
		\item A function that assigns numerical values to the outcomes of a random experiment.
		\item Denoted by uppercase letters (e.g., $X$)
	\end{itemize}
	\item Values of the random variable are denoted by corresponding lowercase letters.
	\begin{itemize}
		\item Corresponding values of the random variable: $x_{1}, x_{2}, x_{3}, \dots$
	\end{itemize}
	\item Random variables may be classified as:
	\begin{description}
		\item[Discrete] The random variable assumes a countable number of distinct values.
		\item[Continuous] The random variable is characterized by (infinitely) uncountable values \win\ any interval.
	\end{description}
	\item Consider an experiment in which two shirts are selected from the production line and each can be defective (D) or non-defective (N).
	\begin{itemize}
		\item Here is the sample space:
		\item The random variable $X$ is the number of defective shirts.
		\item The possible number of defective shirts is the set $\{0, 1, 2\}$.
	\end{itemize}
	\item Since these are the only possible outcomes, this is a discrete random variable.
\end{itemize}

\lo{Describe the probability distribution of a discrete random variable.}
\begin{itemize}
	\item Every random variable is associated \w\ a probability distribution that describes the variable completely.
	\begin{itemize}
		\item A probability mass function is used to describe discrete random variables.
		\item A probability density function is used to describe continuous random variables.
		\item A cumulative distribution function may be used to describe both discrete and continuous random variables.
	\end{itemize}
	\item The probability mass function of a discrete random variable $X$ is a list of the values of $X$ with the associated probabilities, that is, the list of all possible pairs:
	\begin{equation}
		(x, P(X=x))
		\label{eq:probability-mass-function}
	\end{equation}
	\item The cumulative distribution function of $X$ is defined as
	\begin{equation}
		P(X \leq x)
		\label{eq:discrete-cumulative-distribution-function}
	\end{equation}
	\item Two key properties of discrete probability distributions:
	\begin{itemize}
		\item The probability of each value $x$ is a value between 0 and 1, or equivalently
		\[ 0 \leq P(X = x) \leq 1 \]
		\item The sum of the probabilities equals 1.
		In other words,
		\[ \sum_{i} P(X = x_{i}) = 1 \]
		where the sum extends over all values $x_{i}$ of $X$.
	\end{itemize}
	\item A discrete probability distribution may be viewed as a table, algebraically, or graphically.
	\item For example, consider the experiment of rolling a six-sided die.
	A tabular presentation is:
	\begin{table}[H]
		\centering
		\caption{Tabular representation of rolling a six-sided die.}
		\label{tab:six-sided-die}
		\begin{tabular}{*{7}{|c}|}
			\hline
			$x$ & 1 & 2 & 3 & 4 & 5 & 6\\
			\hline
			$P(X=x)$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$\\
			\hline
		\end{tabular}
	\end{table}
	\item Each outcome has an associated probability of $\frac{1}{6}$.
	Thus, the pairs of values and their probabilities form the probability mass function for $X$.
	\item Another tabular view of a probability distribution is based on the cumulative probability distribution.
	\begin{itemize}
		\item For example, consider the experiment of rolling a six-sided die.
		The cumulative probability distribution is
		\begin{table}[H]
			\centering
			\caption{Tabular cumulative probability distribution of rolling a six-sided die.}
			\label{tab:six-sided-die-cumulative}
			\begin{tabular}{*{7}{|c}|}
				\hline
				$x$ & 1 & 2 & 3 & 4 & 5 & 6\\
				\hline
				$P(X=x)$ & $\frac{1}{6}$ & $\frac{2}{6}$ & $\frac{3}{6}$ & $\frac{4}{6}$ & $\frac{5}{6}$ & $\frac{6}{6}$\\
				\hline
			\end{tabular}
		\end{table}
	\end{itemize}
	\item The cumulative probability gives the probability of $X$ being less than or equal to $x$.
	For example, $P(x \leq 4) = \frac{4}{6} = \frac{2}{3}$.
	\item A probability distribution may be expressed algebraically.
	\item For example, for the sid-sided die experiment, the probability distribution of the random variable $X$ is:
	\[ P(X = x) = \left\{ \begin{array}{ll}
		\frac{1}{6} & \text{if } x = 1, 2, 3, 4, 5, 6\\
		0 & \text{otherwise.}
	\end{array} \right. \]
	\item Using this formula, we can find
	\[ \begin{aligned}
		P(X = 5) &= \frac{1}{6}\\
		P(X = 7) &= 0\\
	\end{aligned} \]
	\item A probability distribution may be expressed graphically.
	\begin{itemize}
		\item The values $x$ of $X$ are placed on the horizontal axis and the associated probabilities on the vertical axis.
		\item A line is drawn such that its height is associated \w\ the probability of $x$.
		\item $\dots$
		\item This is a uniform distribution since the bar heights are all the same.
	\end{itemize}
\end{itemize}

\section{Expected Value, Variance, and Standard Deviation}\label{sec:expected-value-variance-and-standard-deviation}
\lo{Calculate and interpret summary measures for a discrete random variable.}
\begin{itemize}
	\item Summary measures for a random variable include the
	\begin{itemize}
		\item Mean (Expected Value)
		\item Variance
		\item Standard Deviation
	\end{itemize}
\end{itemize}
\subsection{Expected Value}\label{subsec:discrete-expected-value}
\[ \begin{aligned}
	\text{Expected Value} &\Leftrightarrow \text{Population Mean}\\
	E(X) &\Leftrightarrow \mu\\
\end{aligned} \]
\begin{itemize}
	\item $E(X)$ is the long-run average value of the random variable over infinitely many independent repetitions of an experiment.
	\item For a discrete random variable $X$ \w\ values $x_{1}, x_{2}, x_{3}, \dots$ that occur with probabilities $P(X = x_{i})$, the expected value of $X$ is
	\begin{equation}
		\begin{aligned}
			E(X) &= \mu\\
			&= \sum_{i} x_{i} \times P(X = x_{i})
		\end{aligned}
		\label{eq:discrete-expected-value}
	\end{equation}
\end{itemize}

\subsection{Variance and Standard Deviation}\label{subsec:variance-and-standard-deviation}
\begin{itemize}
	\item For a discrete random variable $X$ \w\ values $x_{1}, x_{2}, x_{3}, \dots$ that occur \w\ probabilities $P(X = x)$,
	\begin{equation}
		\begin{aligned}
			\text{Var}(X) = \sigma^{2} &= \sum_{i} \left( x_{i} - \mu \right)^{2} P(X = x_{i})\\
			&= \sum_{i} x_{i}^{2} P(X = x_{i}) - \mu_{2}\\
		\end{aligned}
		\label{eq:discrete-variance}
	\end{equation}
	\item The standard deviation is the square root of the variance.
	\begin{equation}
		\text{SD}(X) = \sigma = \sqrt{\sigma^{2}}
		\label{eq:discrete-standard-deviation}
	\end{equation}
\end{itemize}

\subsection{Risk Neutrality and Risk Aversion}\label{subsec:risk-neutrality-and-risk-aversion}
\lo{Differentiate among risk neutral, risk averse, and risk loving consumers.}
\begin{itemize}
	\item Risk average consumers:
	\begin{itemize}
		\item Expect a reward for taking a risk.
		\item May decline a risky prospect even if it offers a positive expected gain.
	\end{itemize}
	\item Risk neutral consumers:
	\begin{itemize}
		\item Completely ignore risk.
		\item Always accept a prospect that offers a positive expected gain.
	\end{itemize}
	\item Risk loving consumers:
	\begin{itemize}
		\item May accept a risky prospect even if the expected gain is negative.
	\end{itemize}
\end{itemize}

\subsection{Application of Expected Value to Risk}\label{subsec:application-of-expected-value-to-risk}
\begin{itemize}
	\item Suppose you have a choice of receiving \$1,000 in cash or receiving a beautiful painting from your grandmother.
	\item The actual value of the painting is uncertain.
	Here is a probability distribution of the possible worth of the painting.
	What should you do?
	\begin{table}[H]
		\centering
		\caption{Painting Value Probabilities}
		\label{tab:painting-expected-value}
		\begin{tabular}{|c|c|}
			\hline
			$x$ & $P(X = x)$\\
			\hline
			\$2,000 & 0.20\\
			\hline
			\$1,000 & 0.50\\
			\hline
			\$500 & 0.30\\
			\hline
		\end{tabular}
	\end{table}
\end{itemize}

\section{Portfolio Returns}\label{sec:portfolio-returns}
\lo{Compute summary measures to evaluate a portfolio's return.}
\begin{itemize}
	\item Investment opportunities often use both:
	\begin{itemize}
		\item Expected return as a measure of reward.
		\item Variance or standard deviation of return as a measure of risk.
	\end{itemize}
	\item Portfolio is defined as a collection of assets such as stocks and bonds.
	\begin{itemize}
		\item Let $X$ and $Y$ two random variables of interest, denoting, say, the returns of two assets.
		\item Since an investor may have invested in both assets, we would like to evaluate the portfolio return formed by a linear combination of $X$ and $Y$.
	\end{itemize}
\end{itemize}

\subsection{Properties of random variables useful in evaluating portfolio returns}\label{subsec:properties-of-random-variables-useful-in-evaluating-portfolio-returns}
\begin{itemize}
	\item Given two random variables $X$ and $Y$,
	\begin{itemize}
		\item The expected value of $X$ and $Y$ is
		\begin{equation}
			E(X+Y) = E(X) + E(Y)
			\label{eq:random-variables-expected-value}
		\end{equation}
		\item The variance of $X$ and $Y$ is
		\begin{equation}
			\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X, Y)
			\label{eq:random-variables-variance}
		\end{equation}
		where $\text{Cov}(X, Y)$ is the covariance between $X$ and $Y$.
		\item For constants $a$, $b$, the formulas extend to
		\[ \begin{aligned}
			E(aX + bY) &= aE(X) + bE(Y)\\
			\text{Var}(aX + bY) &= a^{2}\text{Var}(X) + b^{2}\text{Var}(Y) + 2ab\text{Cov}(X, Y)
		\end{aligned} \]
	\end{itemize}
\end{itemize}

\subsection{Expected return, variance, and standard deviation of portfolio returns}\label{subsec:expected-return-variance-and-standard-deviation-of-portfolio-returns}
\begin{itemize}
	\item Given a portfolio \w\ two assets, Asset $A$ and Asset $B$, the expected return of the portfolio $E(R_{p})$ is computed as:
	\begin{equation}
		E(R_{p}) = w_{A}E(R_{A}) + w_{B}E(R_{B})
		\label{eq:portfolio-expected-return}
	\end{equation}
	where $w_{A}$ and $w_{B}$ are the portfolio weights, $w_{A} + w_{B} = 1$, and $E(R_{A})$ and $E(R_{B})$ are the expected returns on assets $A$ and $B$, respectively.
	\item Using the covariance or the correlation coefficient of the two returns, the portfolio variance of return is:
	\begin{equation}
		\text{Var}(R_{p}) = w_{A}^{2}\sigma_{A}^{2} + w_{B}^{2}\sigma_{B}^{2} + 2w_{A}w_{B} \rho_{AB} \sigma_{A} \sigma_{B}
		\label{eq:portfolio-variance-of-return}
	\end{equation}
	where $\sigma_{A}^{2}$ and $\sigma_{B}^{2}$ are the variances of the returns for Asset $A$ and Asset $B$, respectively,
	$\sigma_{AB}$ is the covariance between the returns for Assets A and B,
	and $\rho_{AB}$ is the correlation coefficient between the returns for Asset $A$ and Asset $B$.
	\begin{equation}
		\rho_{AB} = \frac{\sigma_{AB}}{\sigma_{A}\sigma_{B}}
		\label{eq:correlation-coefficient}
	\end{equation}
\end{itemize}

\section{The Binomial Probability Distribution}\label{sec:the-binomial-probability-distribution}
\lo{Describe the binomial distribution and compute relevant probabilities.}
\begin{itemize}
	\item A binomial random variable is defined as the number of successes achieved in the $n$ trials of a Bernoulli process.
	\begin{itemize}
		\item A Bernoulli process consists of a series of $n$ independent and identical trials of an experiment such that on each trial:
		\begin{itemize}
			\item There are only two possible outcomes:
			\begin{description}
				\item[$p$] probability of a success
				\item[$1-p=q$] probability of a failure
			\end{description}
			\item Each time the trial is repeated, the probabilities of success and failure remain the same.
		\end{itemize}
	\end{itemize}
	\item A binomial random variable $X$ is defined as the number of successes achieved in the $n$ trials of a Bernoulli process.
	\item A binomial probability distribution shows the probabilities associated \w\ the possible values of the binomial random variable (that is, 0, 1, $\dots$, n).
	\begin{itemize}
		\item For a binomial random variable $X$, the probability of $x$ successes in $n$ Bernoulli trials is:
		\begin{equation}
			\begin{aligned}
				P(X = x) &= \left( \begin{array}{c} n \\ x \end{array} \right)p^{x} q^{n-x}\\
				&= \frac{n!}{(n-x)!x!} p^{x} q^{n-x}
			\end{aligned}
			\label{eq:binomial-probability-distribution}
		\end{equation}
		for $x = 0, 1, 2, \dots, n$.
	\end{itemize}
	\item For a binomial distribution:
	\begin{itemize}
		\item The expected value $E(X)$ is:
		\begin{equation}
			E(X) = \mu = np
			\label{eq:binomial-expected-value}
		\end{equation}
		\item The variance Var$(X)$ is:
		\begin{equation}
			\text{Var}(X) = \sigma^{2} = npq
			\label{eq:binomial-variance}
		\end{equation}
		\item The standard deviation SD$(X)$ is:
		\begin{equation}
			\text{SD}(X) = \sigma = \sqrt{npq}
			\label{eq:binomial-standard-deviation}
		\end{equation}
	\end{itemize}
\end{itemize}

\section{The Poisson Probability Distribution}\label{sec:the-poisson-probability-distribution}
\lo{Descrive the Poisson distribution and compute relevant probabilities.}
\begin{itemize}
	\item A binomial random variable counts the number of successes in a fixed number of Bernoulli trials.
	\item In contrast, a Poisson random variable counts the number of successes over a given interval of time or space.
	\begin{itemize}
		\item Examples of a Poisson random variable include:
		\begin{description}
			\item[\Wrt\ time] the number of cars that cross the Brooklyn Bridge between 9:00 am and 10:00 am on a Monday morning.
			\item[\Wrt\ space] the number of defects in a 50-year roll of fabric.
		\end{description}
	\end{itemize}
	\item A random experiment satisfies a Poisson process if:
	\begin{itemize}
		\item The number of successes \win\ a specified time or space interval equals any integer between 0 and $\infty$.
		\item The number of successes in non-overlapping intervals are independent.
		\item The probability that successes occurs in any interval is the same for all intervals of equal size and is proportional to the size of the interval.
	\end{itemize}
	\item For a Poisson random variable $X$, the probability of $x$ successes over a given interval of time or space is:
	\begin{equation}
		P(X = x) = \frac{e^{-\mu}\mu^{x}}{x!} \text{   for } x = 0, 1, 2, \dots
		\label{eq:possion}
	\end{equation}
	where $\mu$ is the mean number of successes and $e \approx 2.718$ is the base of the natural logarithm.
	\item For a Poisson distribution:
	\begin{itemize}
		\item The expected value $E(X)$ is:
		\begin{equation}
			E(X) = \mu
			\label{eq:poisson-expected-value}
		\end{equation}
		\item The variance Var$(X)$ is:
		\begin{equation}
			\text{Var}(X) = \sigma^{2} = \mu
			\label{eq:poisson-variance}
		\end{equation}
		\item The standard deviation SD$(X)$ is:
		\begin{equation}
			\text{SD}(X) = \sigma = \sqrt{\mu}
			\label{eq:poisson-standard-deviation}
		\end{equation}
	\end{itemize}
\end{itemize}
%</Chapter-5>

\end{document}