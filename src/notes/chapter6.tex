\documentclass[
	lecture={6},
	title={Continuous Random Variables}
]{msf502notes}

\begin{document}

\setcounter{chapter}{5}
%<*Chapter-6>
\chapter{Continuous Random Variables}\label{ch:continuous-random-variables}
\begin{objectives}
	\item Describe a continuous random variable.
	\item Describe a continuous uniform distribution and calculate associated probabilities.
	\item Explain the characteristics of the normal distribution.
	\item Use the standard normal table of the $z$-table.
	\item \textbf{Calculate and interpret probabilities or a random variable that follows the normal distribution.}
	\item \textbf{Calculate and interpret probabilities or a random variable that follows the exponential distribution.}
	\item \textbf{Calculate and interpret probabilities or a random variable that follows the lognormal distribution.}
\end{objectives}

\section{Continuous Random Variables and the Uniform Probability Distribution}\label{sec:continuous-random-variables-and-the-uniform-probability-distribution}
\lo{Describe a continuous random variable.}
\begin{itemize}
	\item \hyperref[sec:random-variables-and-discrete-probability-distributions]{Remember that random variables may be classified as}
	\begin{description}
		\item[Discrete] The random variable assumes a countable number of distinct values.
		\item[Continuous] The random variable is characterized by (infinitely) uncountable values \win\ any interval.
	\end{description}
	\item When computing probabilities for a continuous random variable, keep in mind that $P(X=x) = 0$.
	\begin{itemize}
		\item We cannot assign a nonzero probability to each infinitely uncountable value and still have the probabilities sum to one.
		\item Thus, since $P(X=a)$ and $P(X=b)$ both equal zero, the following holds true for continuous random variables:
		\[ P(a \leq X \leq b) = P(a < X < b) = P(a \leq X < b) = P(a < X \leq b) \]
	\end{itemize}
\end{itemize}

\subsection{Probability Density Function $f(x)$ of a continuous random variable $X$}\label{subsec:continuous-probability-density-function}
\begin{itemize}
	\item Describes the relative likelihood that $X$ assumes a value \win\ a general interval (e.g., $P(a \leq X \leq b)$), where
	\begin{itemize}
		\item $f(x) > 0$ for all possible values of $X$.
		\item The area under $f(x)$ over all values of $x$ equals 1.
	\end{itemize}
\end{itemize}

\subsection{Cumulative Density Function $F(x)$ of a continuous random variable $X$}\label{subsec:continuous-cumulative-density-function}
\begin{itemize}
	\item For any value $x$ of the random variable $X$, the cumulative distribution function $F(x)$ is computes as:
	\[ F(X) = P(X \leq x) \]
	\item As a result:
	\[ P(a \leq X \leq b) = F(b) - F(a) \]
\end{itemize}

\subsection{The Continuous Uniform Distribution}\label{subsec:the-continuous-uniform-distribution}
\lo{Describe a continuous uniform distribution and calculate associated probabilities.}

\begin{itemize}
	\item Describe a random variable that has an equally likely chance of assuming a value \win\ a specified range.
	\item Probability density function:
	\begin{equation}
		f(x) = \left\{ \begin{array}{ll}
						   \frac{1}{b - a} & \text{ for } a \leq x \leq b, \text{ and}\\
						   0 & \text{ for } x < a \text{ or } x > b
		\end{array} \right.
		\label{eq:continuous-uniform-pdf}
	\end{equation}
	where $a$ and $b$ are the lower and upper limits, respectively.
	\item The expected value and standard deviation of $X$ are:
	\begin{equation}
		E(X) = \mu = \frac{a + b}{2}
		\label{eq:continuous-uniform-ev}
	\end{equation}
	\begin{equation}
		\begin{aligned}
			\text{SD}(X) &= \sigma\\
			&= \sqrt{\frac{(b-a)^{2}}{12}}
		\end{aligned}
		\label{eq:continuous-uniform-sd}
	\end{equation}
\end{itemize}

\subsection{Graph of the continuous uniform distribution}\label{subsec:graph-of-the-continuous-uniform-distribution}
\begin{itemize}
	\item The values of $a$ and $b$ on the horizontal axis represent the lower and upper limits, respectively.
	\item The height of the distribution does not directly represent a probability.
	\item It is the area under $f(x)$ that corresponds to probability.
\end{itemize}

Cumulative function:
\[ \begin{aligned}
	   P(X > x_{1}) &= \text{base} \times \text{height}\\
	   &= (b - x_{1}) \times \frac{1}{b-a}
\end{aligned} \]

\section{The Normal Distribution}\label{sec:the-normal-distribution}
\begin{itemize}
	\item For a random variable $X$ with mean $\mu$ and variance $\sigma^{2}$:
	\begin{equation}
		f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp \left( -\frac{(x - \mu)^{2}}{2\sigma^{2}} \right)
		\label{eq:normal-distribution}
	\end{equation}
\end{itemize}

\subsection{The Normal Distribution}\label{subsec:the-normal-Distribution}
\lo{Explain the characteristics of the normal distribution.}

\begin{itemize}
	\item Symmetric
	\item Bell-shaped
	\item Closely approximates the probability distribution of a wide range of random variables, such as the
	\begin{itemize}
		\item Heights and weights of newborn babies
		\item Scores on SAT
		\item Cumulative debt of college graduates
	\end{itemize}
	\item Serves as the cornerstone of statistical inference.
\end{itemize}

\subsection{Characteristics of the Normal Distribution}\label{subsec:characteristics-of-the-normal-distribution}
\begin{itemize}
	\item Symmetric about its mean
	\begin{itemize}
		\item Mean = Median = Mode
	\end{itemize}
	\item Asymptotic--that is, the tail gets closer and closer to the horizontal axis but never touches it.
	\item The normal distribution is completely described by two parameters: $\mu$ and $\sigma^{2}$.
	\begin{description}
		\item[$\mu$] is the population mean which describes the central location of the distribution.
		\item[$\sigma^{2}$] is the population variance which describes the dispersion of the distribution.
	\end{description}
\end{itemize}

\subsection{Probability Density Function of the Normal Distribution}\label{subsec:probability-density-function-of-the-normal-distribution}
\begin{itemize}
	\item For a random variable $X$ \w\ mean $\mu$ and variance $\sigma^{2}$:
	\begin{equation}
		f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{(x - \mu)^{2}}{2\sigma^{2}} \right)
		\label{eq:normal-pdf}
	\end{equation}
\end{itemize}

\subsection[$Z$-Distribution]{The Standard Normal (Z) Distribution}\label{subsec:the-standard-normal-(z)-distribution}
\lo{Use the standard normal table of the $z$-table.}
\begin{itemize}
	\item A special case of the normal distribution:
	\begin{itemize}
		\item Mean $\mu$ is qual to zero ($E(X) = 0$).
		\item Standard deviation $\sigma$ is equal to 1 (SD$(Z) = 1$).
	\end{itemize}
\end{itemize}

\subsection[$Z$-Table]{Standard Normal Table ($Z$-Table)}\label{subsec:z-table)}
\begin{itemize}
	\item Gives the cumulative probabilities $P(Z \leq z)$ for positive and negative values of $z$.
	\item Since the random variable $Z$ is symmetric about its mean of 0,
	\[ P(Z < 0) = P(Z > 0) = 0.5 \]
	\item To obtain the $P(Z < z)$, read down the $z$-column first, then across the top.
\end{itemize}

\subsection{Finding the Probability for a Given $z$-Value}\label{subsec:finding-the-probability-for-a-given-$z$-value}
\begin{itemize}
	\item Transform normally distributed random variables into standard normal random variables and use the $z$-table to compute the relevant probabilities.
	\item The $z$-table provides cumulative probabilities $P(Z \leq z)$ for a given $z$.
\end{itemize}

\section{Solving Problems \w\ the Normal Distribution}\label{sec:solving-problems-w-the-normal-distribution}
\lo{Calculate and interpret probabilities or a random variable that follows the normal distribution.}

\subsection{The Normal Transformation}\label{subsec:the-normal-transformation}
\begin{itemize}
	\item Any normally distributed random variable $X$ with mean $\mu$ and standard deviation $\sigma$ can be transformed into the standard normal random variable $Z$ as:
	\begin{equation}
		Z = \frac{X - \mu}{\sigma} \text{ \w\ corresponding values } z = \frac{x - \mu}{\sigma}
		\label{eq:normal-transformation}
	\end{equation}
	\item As constructed: $E(Z) = 0$ and SD$(Z) = 1$.
	\item A $z$-value specifies by how many standard deviations the corresponding $x$ value falls above ($z > 0$) or below ($z < 0$) the mean.
	\begin{itemize}
		\item A positive $z$ indicates by how many standard deviations the corresponding $x$ lies above $\mu$.
		\item A zero $z$ indicates that the corresponding $x$ equals $\mu$.
		\item A negative $z$ indicates by how many standard deviations the corresponding $x$ lies below $\mu$.
	\end{itemize}
\end{itemize}

\subsection[Inverse $z$-Transformation]{Use the Inverse Transformation to Compute Probabilities for Given $x$ values}\label{subsec:use-the-inverse-z-transformation}
\begin{itemize}
	\item A standard normal variable $Z$ can be transformed to the normally distributed random variable $X$ \w\ mean $\mu$ and standard deviation $\sigma$ as
	\begin{equation}
		X = \mu + Z\sigma \text{ \w\ corresponding values } x = \mu + z\sigma
		\label{eq:z-inverse-transform}
	\end{equation}
\end{itemize}

\section{Other Continuous Probability Distributions}\label{sec:other-continuous-probability-distributions}
\lo{Calculate and interpret probabilities or a random variable that follows the exponential distribution.}

\subsection{Exponential Distribution}\label{subsec:exponential-distribution}
\begin{itemize}
	\item A random variable $X$ follows the exponential distribution if its probability density function is:
	\begin{equation}
		f(x) = \lambda e^{-\lambda x} \text{ for } x \geq 0
		\label{eq:exponential-pdf}
	\end{equation}
	where $\lambda$ is the rate parameter and $E(X)=\text{SD}(X) = \frac{1}{\lambda}$.
	\item The cumulative distribution function is:
	\begin{equation}
		P(X \leq x) = 1 - e^{-\lambda x}
		\label{eq:exponential-cumulative-distribution}
	\end{equation}
\end{itemize}

%The exponential distribution is based entirely on one parameter $\lambda > 0$, as illustrated below.

\subsection[Lognormal Distribution]{The Lognormal Distribution}\label{subsec:lognormal-distribution}
\lo{Calculate and interpret probabilities or a random variable that follows the lognormal distribution.}

\begin{itemize}
	\item Defined for a positive random variable, the lognormal distribution is positively skewed.
	\item Useful for describing variables such as
	\begin{itemize}
		\item Income
		\item Real estate values
		\item Asset prices
	\end{itemize}
	\item Failure rate may increase or decrease over time.
	\item Let $X$ be a normally distributed random variable \w\ mean $\mu$ and standard deviation $\sigma$.
	The random variable $Y = e^{X}$ follows the lognormal distribution \w\ a probability density function as
	\begin{equation}
		f(y) = \frac{1}{y\sigma\sqrt{2\pi}} \exp\left( -\frac{\left( \ln(y) - \mu \right)^{2}}{2\sigma^{2}} \right) \text{ for } y > 0
		\label{eq:lognormal-pdf}
	\end{equation}
	\item The lognormal distribution is clearly positively skewed for $\sigma > 1$.
	For $\sigma < 1$, the lognormal distribution somewhat resembles to normal distribution.
\end{itemize}

\subsection[EV and SD of Lognormal and Normal Distributions]{Expected values and standard deviations of the lognormal and normal distributions}\label{subsec:expected-values-and-standard-deviations-of-the-lognormal-and-normal-distributions}
\begin{itemize}
	\item Let $X$ be a normal random variable \w\ mean $\mu$ and standard deviation $\sigma$ and let $Y = e^{X}$ by the corresponding lognormal variable.
	The mean $\mu_{y}$ and standard deviation $\sigma_{Y}$ or $Y$ are derived as:
	\begin{equation}
		\mu_{Y} = \exp\left( \frac{2\mu + \sigma^{2}}{2} \right)
		\label{eq:lognormal-mean}
	\end{equation}
	\begin{equation}
		\sigma_{Y} = \sqrt{ \left( \exp(\sigma^{2}) - 1 \right) \exp\left( 2\mu + \sigma^{2} \right) }
		\label{eq:lognormal-standard-deviation}
	\end{equation}
	\item Equivalently, the mean and standard deviation of the normal variable $X = \ln(Y)$ are derived as
	\begin{equation}
		\mu = \ln\left( \frac{\mu_{Y}^{2}}{\sqrt{\mu_{Y}^{2} + \sigma_{Y}^{2}}} \right)
		\label{eq:normal-mean}
	\end{equation}
	\begin{equation}
		\sigma = \sqrt{\ln\left( 1 + \frac{\sigma_{Y}^{2}}{\mu_{Y}^{2}} \right)}
		\label{eq:normal-standard-deviation}
	\end{equation}
\end{itemize}
%</Chapter-6>

\end{document}